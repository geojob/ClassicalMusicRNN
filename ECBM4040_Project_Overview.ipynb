{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import RNNModel\n",
    "import os\n",
    "import multi_training\n",
    "from midi_to_statematrix import midiToNoteStateMatrix\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this project was to generate classical music using a stacked LSTM based RNN network. The snippets below show the process of importing the data in the form of midi files and the parsed by the conversion algorithm to change it into  a state matrix form.The following two snippets shows the overall structure and the method in which the underlying util functions work. The model as created and trained separately, therefore, the code below is simply to show how the data was imported and changed to a statematrix before being applied through the different layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded appass_2\n",
      "Loaded appass_3\n",
      "Loaded bach_846\n",
      "Loaded bach_847\n",
      "Loaded bach_850\n",
      "Loaded beethoven_hammerklavier_1\n",
      "Loaded beethoven_hammerklavier_1_format0\n",
      "Loaded beethoven_les_adieux_1\n",
      "Loaded beethoven_les_adieux_2\n",
      "Loaded beethoven_opus10_2\n",
      "Loaded beethoven_opus10_3\n",
      "Loaded beethoven_opus22_1\n",
      "Loaded beethoven_opus22_4\n",
      "Loaded beethoven_opus90_2\n",
      "Loaded chpn-p1\n",
      "Loaded chpn-p14\n",
      "Loaded chpn-p15\n",
      "Loaded chpn-p16\n",
      "Loaded chpn-p2\n",
      "Loaded chpn-p20\n",
      "Loaded chpn-p23\n",
      "Loaded chpn-p3\n",
      "Loaded chpn-p4\n",
      "Loaded chpn-p8\n",
      "Loaded chpn-p9\n",
      "Loaded chpn_op10_e01\n",
      "Loaded chpn_op10_e05\n",
      "Loaded chpn_op10_e12\n",
      "Loaded chpn_op25_e1\n",
      "Loaded chpn_op25_e11\n",
      "Loaded chpn_op25_e12\n",
      "Loaded chpn_op25_e2\n",
      "Loaded chpn_op25_e4\n",
      "Loaded chpn_op27_1\n",
      "Loaded chpn_op35_1\n",
      "Loaded chpn_op35_3\n",
      "Loaded chpn_op35_4\n",
      "Loaded chpn_op66\n",
      "Loaded debussy_cc_1\n",
      "Loaded debussy_cc_2\n",
      "Loaded debussy_cc_4\n",
      "Loaded debussy_cc_6\n",
      "Loaded DEB_PASS\n",
      "Loaded deb_prel\n",
      "Loaded mond_1\n",
      "Loaded mond_3\n",
      "Loaded mz_311_1\n",
      "Loaded mz_311_2\n",
      "Loaded mz_330_1\n",
      "Loaded mz_330_3\n",
      "Loaded mz_331_3\n",
      "Loaded mz_332_2\n",
      "Loaded mz_333_1\n",
      "Loaded mz_333_3\n",
      "Loaded mz_545_1\n",
      "Loaded mz_545_3\n",
      "Loaded mz_570_2\n",
      "Loaded mz_570_3\n",
      "Loaded pathetique_1\n",
      "Loaded pathetique_2\n",
      "Loaded pathetique_3\n",
      "Loaded ty_februar\n",
      "Loaded ty_juli\n",
      "Loaded ty_juni\n",
      "Loaded ty_maerz\n",
      "Loaded ty_november\n",
      "Loaded ty_oktober\n",
      "Loaded ty_september\n",
      "Loaded waldstein_1\n",
      "Loaded waldstein_3\n",
      "\n",
      "Number of training pieces =  60\n",
      "Number of validation pieces =  10\n",
      "Sample of State Input Batch: shape =  (5, 90, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "num_validation_pieces=10\n",
    "\n",
    "training_pieces = multi_training.loadPieces(\"./music\",128)\n",
    "\n",
    "# Set aside a random set of pieces for validation purposes\n",
    "validation_pieces={}\n",
    "for v in range(num_validation_pieces):\n",
    "    index = random.choice(list(training_pieces.keys()))\n",
    "    validation_pieces[index] = training_pieces.pop(index)\n",
    "    \n",
    "    \n",
    "print('')\n",
    "print('Number of training pieces = ', len(training_pieces))    \n",
    "print('Number of validation pieces = ', len(validation_pieces))     \n",
    "    \n",
    "    \n",
    "\n",
    "# Generate sample Note State Matrix for dimension measurement and numerical checking purposes\n",
    "# (Using external code to generate the Note State Matrix but using our own NoteInputForm (as defined in author's code) function\n",
    "practice_batch_size = 5\n",
    "practice_num_timesteps = 128\n",
    "\n",
    "_, sample_state = multi_training.getPieceBatch(training_pieces, practice_batch_size, practice_num_timesteps)\n",
    "sample_state = np.array(sample_state)\n",
    "sample_state = np.swapaxes(sample_state, axis1=1, axis2=2)\n",
    "print('Sample of State Input Batch: shape = ', sample_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Expand shape =  (5, 90, 128, 80)\n",
      "Time-wise output shape =  (5, 90, 128, 200)\n",
      "y_out shape =  (5, 90, 128, 2)\n",
      "generated samples shape =  (5, 90, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "num_notes = sample_state.shape[1]\n",
    "batch_size = practice_batch_size\n",
    "num_timesteps = sample_state.shape[2]\n",
    "midilowpitch = 18\n",
    "midihighpitch = 107\n",
    "Note_State_Expand = RNNModel.Input_Kernel(sample_state.astype('float32'), midilowpitch, midihighpitch, 0)\n",
    "print('Note_State_Expand shape = ', Note_State_Expand.get_shape())\n",
    "\n",
    "num_t_units=[200,200]\n",
    "timewise_state_val=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    c_t = tf.convert_to_tensor(np.zeros((batch_size*num_notes, num_t_units[i])).astype('float32'))\n",
    "    h_t = tf.convert_to_tensor(np.zeros((batch_size*num_notes, num_t_units[i])).astype('float32'))\n",
    "    timewise_state_val.append([h_t, c_t])\n",
    "\n",
    "timewise_state = tuple(timewise_state_val)\n",
    "timewise_out, timewise_state_out = RNNModel.LSTM_TimeWise_Training_Layer(input_data=Note_State_Expand, state_init=timewise_state, output_keep_prob=0.5)\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "\n",
    "\n",
    "num_n_units = [100, 100]\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c_n = tf.convert_to_tensor(np.zeros((batch_size*num_timesteps, num_n_units[i])).astype('float32')) \n",
    "    h_n = tf.convert_to_tensor(np.zeros((batch_size*num_timesteps, num_n_units[i])).astype('float32'))\n",
    "    notewise_state.append([h_n, c_n])\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "y_out, note_gen_out = RNNModel.LSTM_NoteWise_Layer(timewise_out, state_init=notewise_state, output_keep_prob=0.5)\n",
    "\n",
    "p_out = tf.sigmoid(y_out)\n",
    "print('y_out shape = ', y_out.get_shape())\n",
    "print('generated samples shape = ', note_gen_out.get_shape())\n",
    "\n",
    "#print(sample_state)\n",
    "#loss, log_likelihood = RNNModel.Loss_Function(sample_state.astype('float32'), y_out)\n",
    "#optimizer = tf.keras.optimizers.Adadelta().minimize(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
